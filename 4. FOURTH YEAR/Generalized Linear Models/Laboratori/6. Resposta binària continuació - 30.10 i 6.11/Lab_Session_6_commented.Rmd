---
title: "Lab Session 6"
author: "Lidia Montero, Josep Anton Sanchez & Jordi Cortes"
date: "October 2018"
output:
  html_document: default
---

## Prepare Dataset and load packages

```{r, warning=FALSE, message=FALSE}
load("Eleccions_92.RData")
options(contrasts=c("contr.treatment","contr.poly"))
library(car)
library(MASS)
library(AER)
library(effects)
library(lmtest)
library(FactoMineR)
library(rms)
library(fmsb)
library(ROCR)
library(AUC)
```

# Define response variable (pres) and factors properly. 

New variables will be created: they will be use further.

```{r}
### Punt 1
summary(elecc92)

elecc92$inter <- factor(elecc92$inter,levels=c("none","some","high"))
elecc92$close <- factor(elecc92$close,labels=c("Close-No","Close-Yes"))
elecc92$sat <- factor(elecc92$sat,labels=c("Sat-No","Sat-Yes"))
elecc92$vota <- factor(elecc92$pres,labels=c("Pres-No","Pres-Yes"))
elecc92$c.age <- cut(elecc92$age,breaks=c(16,29,39,59,91))
elecc92$ones <- rep(1,length(elecc92$pres))
elecc92$c.edu <- cut(elecc92$educ,breaks=c(-1,11,12,15,17))
elecc92$p <- factor(elecc92$p,levels=c('ind','weak','strong'))

elecc92$id <- NULL # Not use

summary(elecc92)
```

# Point 1: Exploratory Data Analysis

Categories are reasonably well balanced

```{r, fig.height=3.5}
par(mfrow=c(1,2),las=2)
barplot(table(elecc92$c.age))
barplot(table(elecc92$c.edu))
```

```{r, fig.height=6}
par(mfrow=c(1,2),las=1)
Boxplot(age~pres,data=elecc92,col=c(2,3))
Boxplot(educ~pres,data=elecc92,col=c(2,3))

par(mfrow=c(3,2),las=1)
plot(vota~inter,data=elecc92,col=c(2,3))
plot(vota~close,data=elecc92,col=c(2,3))
plot(vota~sat,data=elecc92,col=c(2,3))
plot(vota~inter,data=elecc92,col=c(2,3))
plot(vota~c.age,data=elecc92,col=c(2,3))
plot(vota~c.edu,data=elecc92,col=c(2,3))
```


# Feature Selection

```{r}
summary(elecc92)
catdes(elecc92,9)  # 9 is the index of variable vota
```

\pagebreak

# Point 2: Aggregated vs Desaggregated data for binary response models

Disaggregated data

```{r}
m1 <- glm(pres~age,data=elecc92,family=binomial)
summary(m1)

par(mfrow=c(2,2))
plot(m1)
```

Function to create an aggregated dataset using classes defined by age

```{r,echo=FALSE}
# Codi de la rutina
agregacio <- function(dfin, nve, formula1, formula2){
# Exemple crida: dfage <- agregacio(elecc92,1,as.formula(uns~age),as.formula(pres~age))
# Retorna dataframe: dfage amb age, m, ypos, yneg. 
#
# Formula1 ha de ser uns~var1+...+var_nve
# Formula2 ha de ser resposta~var1+...+var_nve.Resposta ha de ser num?rica.
# Requereix que dfin,data.frame d'entrada contingui una columna amb uns
# Retorna: dfout, data.frame amb var1 , ..., var_nve, m, ypos, yneg.
# Valid per nve arbitrari > 0

taulam <- xtabs(formula1,exclude=NULL,dfin,drop.unused.levels=TRUE);
taulap <- xtabs(formula2,exclude=NULL,dfin,drop.unused.levels=TRUE);

dfout <- as.data.frame(taulam);
dfaux <- as.data.frame(taulap);

names(dfout)[nve+1] <- "m";
names(dfaux)[nve+1] <- "ypos";
attach(dfaux);
dfout <- data.frame(dfout,ypos);
dfout$m <- as.integer(dfout$m)
dfout$yneg <- as.integer(dfout$m-dfout$ypos);
attach(dfout);
dfout <- dfout[m>0,]
}
```

# Aggregated data

In this case, it is possible to aggregate by a continous variable because it is discretized and the sample size is big enough

```{r}
dfage <- agregacio(elecc92,1,as.formula(ones~age),as.formula(pres~age))
summary(dfage)
dfage$age <- as.numeric(levels(dfage$age))[dfage$age]
head(dfage)
summary(dfage)
```

In the model, the coefficients are the same that those ones with dissagragated data, but not the deviance and degrees of freedom.

```{r}
m1a <- glm(cbind(ypos,yneg)~age,data=dfage,family=binomial)
summary(m1a)
```

# Goodness of fit

When disaggregated data is used then $m_i = 1$ and asymptotic theory does not apply, as a rule of thumb at a fully disaggregated level for data, a model is good if Deviance or Pearson $\chi^2$ statistics are similar to degrees of freedom of the model. Large values indicate a lack of fit of the model.

```{r}
1 - pchisq(m1a$dev,m1a$df.res)  # Aggregated data model
m1$dev;m1$df.res                # Disaggregated data
```


# Interpretation

The exponential of the coefficient represents the OR on the positive response for a 1-year increase.

```{r}
# Interpretacio efecte age en m1
cat('An increase of one year in age is associated with an increase of', round(exp(coef(m1)['age']),3), 'in the odds of positive response\n')    # Increment 1 any
cat('An increase of 10 years in age is associated with an increase of', round(10*exp(coef(m1)['age']),3), 'in the odds of positive response\n') # Increment 10 anys
```


Let's check the fit using a manual plot and also residual analysis methods available in package car. There is a non-linear relationship between age and the logodds of the positive response. 

By hand:

```{r}
par(mfrow=c(1,1))
dfage$olog <- log((dfage$ypos+0.5)/(dfage$yneg+0.5))    # logodds
plot(dfage$age,dfage$olog,pch=19)                       # points
points(dfage$age,m1a$linear.predictor,col=2,lwd=1.5)    # Linear relationship
lines(lowess(dfage$age,dfage$olog,f=0.5),col=3)         # high smooth        
lines(lowess(dfage$age,dfage$olog,f=0.75),col=4,lwd=2)  # medium smooth        
lines(lowess(dfage$age,dfage$olog,f=1.0),col=5)         # low smooth        
```

Another equivalent plot done with the function *scatterplot* of the *car* package:

```{r}
scatterplot(olog~age,dfage,col=1,regLine=list(col=4),smooth=list(col.smooth=3,col.var=3))
```

Plot effects using the function *allEffects*:

```{r}
plot(allEffects(m1),ask=FALSE)
```

```{r warning=FALSE}
residualPlots(m1a, layout=c(1, 2))                                  # Pearson residuals versus predictors
marginalModelPlots(m1a,id=list(method=abs(cooks.distance(m1)),n=5)) 
```

\pagebreak

# Point 3: Exercise

3.	Ajusteu un model de regressió logística amb predictor lineal els termes d'ordre 1 i 2 de l'EDAT (Models  M1-2, M1-3, variants de M1) (els ordres no lineals obteniu-los sempre respecte la tendència central de la variable o empreu la comanda poly(EDAT,k)). 

Dos metodes: amb la funcio $I$ o amb la funcio $poly$. Es centra per a que tingui sentit el valor nul.


```{r}
m1.1 <-  glm(pres ~ age,                                 data=elecc92,family=binomial)  # Relació lineal
m1.2 <-  glm(pres ~ age + I((age-42)^2),                 data=elecc92,family=binomial)  # Relació quadràtica
m1.3 <-  glm(pres ~ age + I((age-42)^2) + I((age-42)^3), data=elecc92,family=binomial)  # Relació cúbica
m1.2p <- glm(pres ~ poly(age,2,raw=TRUE),                data=elecc92,family=binomial)  # Relació quadràtica
m1.3p <- glm(pres ~ poly(age,3),                         data=elecc92,family=binomial)  # Relació cúbica
```

a.	Contrasteu formalment la significació del terme d'ordre 3 de l'edat: segons l'estadístic de Wald i segons el contrast de la deviança.

```{r}
anova(m1.2,m1.3,test="Chisq")              # Deviance
anova(m1.2p,m1.3p,test="Chisq")            # Deviance --> Equivalent to previous


waldtest(m1.2,m1.3,test="Chisq")           # Wald
linearHypothesis(m1.3p,"poly(age, 3)3=0")  # Wald --> Equivalent to previous
```

b.	Contrasteu formalment la significació del terme d'ordre 2 de l'edat: segons l'estadístic de Wald i segons el contrast de la deviança. 
```{r}
anova(m1,m1.2,test="Chisq")      # Deviance
waldtest(m1,m1.2,test="Chisq")   # Wald
```

c.	Useu sobre el conjunt de dades desagregat la comanda: marginalModelPlots() en m1 i model triat.
```{r warnings=FALSE}
plot(allEffects(m1.2p),ask=FALSE)

par(mfrow=c(2,2))
marginalModelPlots(m1.2p,id=list(method=abs(cooks.distance(m1.2p)),n=5)) 
summary(m1.2p)
```

d.	Feu una diagnosi estàndard del model desagregat triat (m1): residualPlots()
```{r}
residualPlots(m1.2p, layout=c(1, 2))
```

4.	Considereu l'agrupació de l'EDAT en categories <30, 30-39, 40-59, 60+. Diem-li Model (M2).  Tornarem a calcular el model m2 amb dades desagregades (i si en teniu ganes m2a amb dades agregades).
a.	Feu una diagnosi estàndard del model desagregat (m2c): residualPlots(m2c)
b.	Representeu el logits empírics/ajustats en funció de l'EDAT Categoritzada en les dades agregades (diagnosi artesanal). Pistes: Us ho podeu estalviar examinant atentament el sumari del model agregat m2a.
```{r warnings=FALSE}
m1c <- glm(pres~c.age,data=elecc92,family=binomial)
summary(m1c)
exp(coef(m1c)['c.age(39,59]'])          # OR for this category in respect to reference
residualPlots(m1c , layout=c(1, 2))
marginalModelPlots(m1c,id=list(method=abs(cooks.distance(m1c)),n=5)) 
```

5.	Quin tractament us sembla més adient per la variable EDAT: com a covariable (fins a quin terme d'ordre) o com a factor. Justifiqueu estadísticament la resposta.

Els models **No són niuats**, per tant no podem usar la deviança.

```{r}
AIC(m1,m1.2p,m1c)
BIC(m1,m1.2p,m1c)
```
6.	Ara estudiarem la introducció de la variable EDUCACIÓ en el model que ja conté l'EDAT (en el seu millor tractament). Per començar es treballarà amb l'EDUCACIÓ com a covariant.
a.	Afegiu un terme lineal d'EDUCACIÓ en el millor model anterior amb l'EDAT.

```{r}
m3n.1  <- glm(pres ~ poly(age,2) + educ, data=elecc92,family=binomial)
summary(m3n.1)
```

b.	Interpreteu el coeficient estimat en termes dels logodds i odds. 
```{r}
b_edu <-  round(coef(m3n.1)['educ'],3) # Increment en logodd
OR_edu <- round(exp(b_edu),3)          # Increment en odds --> OR
cat('An increase of 1 year in the education is associated with an increase of',b_edu,'in the logodds\n')
cat('An increase of 1 year in the education is associated with an increase of',OR_edu,'in the odds\n')
```


c.	Contrasteu la hipòtesi que l'efecte de EDUCACIÓ és lineal mitjançant la introducció d'un terme d'ordre 2 en el model. I el terme d'ordre 3, és significatiu? Pareu a l'ordre 3.

S'observa que tant el terme d'ordre 2 com el terme d'ordre 3 són significatius.

```{r}
m3n.2  <- glm(pres ~ poly(age,2) + poly(educ,2),data=elecc92,family=binomial)
m3n.3  <- glm(pres ~ poly(age,2) + poly(educ,3),data=elecc92,family=binomial)

anova(m3n.1,m3n.2,test="Chisq")  # Test de la deviança
anova(m3n.2,m3n.3,test="Chisq")  # Test de la deviança
```

d.	Trieu el millor model que empra l'EDAT i la covariant EDUCACIÓ: li direm (m3n). No cal treballar amb la versió agregada tret que vulgueu fer diagnosi artesanal.

```{r}
m3n <- m3n.3
```

e.	Useu les eines standard d'anàlisi de residus: marginalModelPlots() i residualPlots().
```{r warnings=FALSE}
residualPlots(m3n , layout=c(1, 3))
marginalModelPlots(m3n,id=list(method=abs(cooks.distance(m3n)),n=5)) 
```

7.	Considereu una agrupació dels anys d'educació (EDUCACIÓ Categoritzada) en 4 grups: <12, 12, 13-15, 16+. Estimeu el model de regressió logística amb els termes i tractament adient de  l'edat i el factor EDUCACIÓ. Quina és la millor manera de tractar els anys d'educació? Li direm (M4).
i.	Assageu rectes de l'edat amb pendents idèntics per cada categoría d'EDUCACIO
ii.	Assageu rectes de l'edat amb pendents diferents per cada categoría d'EDUCACIO
iii.Assageu paràboles de l'edat amb idèntica corbatura per cada categoría d'EDUCACIO 
iv.	Assageu paràboles de l'edat amb diferent corbatura per cada categoría d'EDUCACIO
v.	Estrictament per inferència, quin us sembla el tractament més apropiat.
```{r}
m4.1  <-glm(pres ~ age + c.edu,        data=elecc92,family=binomial) # Model i)
m4.2  <-glm(pres ~ age * c.edu,        data=elecc92,family=binomial) # Model ii)  
m4.3  <-glm(pres ~ poly(age,2) + c.edu,data=elecc92,family=binomial) # Model iii)
m4.4  <-glm(pres ~ poly(age,2) * c.edu,data=elecc92,family=binomial) # Model iv)


anova(m4.1,m4.2,test="Chisq")    # El terme d'interacció sembla necessari
anova(m4.1,m4.3,test="Chisq")    # El terme quadràtic de l'edat sembla necessari
# anova(m4.2,m4.3,test="Chisq")  # Incorrecte --> No es poden comparar perquè no són niuats
anova(m4.3,m4.4,test="Chisq")    # Ambdos termes són nessaris
anova(m4.2,m4.4,test="Chisq")    # Ambdos termes són nessaris
```

Effects. Probability of positive response is higher in those individuals with more years of education. The trend is poitive along years in individuals with less eduaction: older implies more chances to vote. On the other hand, older persons with higher education (category from 15 to 17 years of eduaction) have lower probability to vote. 

```{r}
plot(allEffects(m4.4),ask=FALSE)
```

```{r warnings=FALSE}
residualPlots(m4.4 , layout=c(1, 3))
marginalModelPlots(m4.4,id=list(method=abs(cooks.distance(m4.4)),n=5),layout=c(2,2)) 
scatterplot(log((pres+0.05)/(1-pres+0.05)) ~ age|c.edu,smooth=TRUE,data=elecc92) # ,col=c(0,0,0,1) --> To see only one variable
```





8.	Quina és la millor manera de tractar els anys d'educació, un cop l'EDAT ja ha estat incorporada en el model?

Comparing models by AIC and BIC
According to BIC, it is better not to use the term of interaction, but according to AIC and also with deviance test it is a better option to kae it into account.

```{r warnings=FALSE}
BIC(m3n,m4.1,m4.2,m4.3,m4.4)
AIC(m3n,m4.1,m4.2,m4.3,m4.4)
```


# Interpretation of the selected model

```{r warnings=FALSE}
summary(m4.4)
```

9.	Afegir al model les preferències partidistes. Analitzar els coeficients estimats i suggerir com es podria recodificar aquesta variable per simplificar la interpretació del model i estalviar un quants graus de llibertat (heu de veure que amb màxim 3 categories és suficient). Reajustar el model i reinterpretar els coeficients de la variable codificada.

Crear nova variable:

```{r}
elecc92$party <- as.factor(paste(elecc92$p,elecc92$arty))
summary(elecc92)
m6.1 <- glm(pres ~ poly(age,2)*c.edu + party, family=binomial, data=elecc92)
summary(m6.1)
```

- New categorization:
    - *ind dem* or *ind rep* or *weak dem* or *weak rep* $\rightarrow$ *weak*
    - *strong dem* or *strong rep* $\rightarrow$ *strong*
    - *ind ind* $\rightarrow$ *ind*

```{r}
# Agrupacio de categories
elecc92$partit <- rep("weak",length(elecc92$party))
elecc92$partit[elecc92$party=="strong rep" | elecc92$party=="strong dem"] <- "strong"
elecc92$partit[elecc92$party=="ind ind"] <- "ind"
elecc92$partit <- factor(elecc92$partit,levels=c("ind","weak","strong"))

m6.2 <- glm(pres ~ poly(age,2)*c.edu + partit, family=binomial, data=elecc92)
summary(m6.2)

anova(m6.2,m6.1,test="Chisq")

plot(allEffects(m6.2),ask=FALSE)
m6 <- m6.2
```

10.	Introduïu la variable *grau d'interès* en les eleccions en el model. Contrasteu la significació del seu efecte principal emprant: test de Wald (si el paquet estadístic us ho permet) i el test de la deviança. Afirmaríeu que la principal raó per la que la gent jove vota menys és que no estan interessats en les eleccions?

```{r}
elecc92$inter <- ordered(elecc92$inter,levels=c("none","some","high"))
m7 <- glm(pres~poly(age,2)*c.edu + partit + inter, family=binomial, data=elecc92)
summary(m7)

plot(allEffects(m7),ask=F)
anova(m6,m7,test="Chi")      # Deviance test
anova(m6,m7,test="Cp")       # Mallows' Cp statistic is closely related to AIC: AIC(m6,m7)
waldtest(m6,m7,test='Chisq') # Wald test 
```

11.	Introduïu en el model un terme d'interacció entre el 'grau d'interès' i les 'preferències partidistes'. Contrasteu la significació de la interacció mitjançant el test de deviança. Expliqueu detalladament, si hi ho trobeu evidència, com funciona la interacció.

```{r}
m8 <- glm(pres~poly(age,2)*c.edu + partit*inter, family=binomial, data=elecc92)
summary(m8)
anova(m7,m8,test="Chisq")
```

12.	Hi ha alguna evidència que, després d'introduir el factor de 'proximitat entre els candidats' en el model TREBALLAT FINS EL MOMENT (EDAT, EDUCACIO, PREFERÈNCIES PARTIDISTES, GRAU D'INTERÈS), les persones que creuen que les eleccions són ajustades tinguin una major incidència de vot?

```{r}
m8 <- glm(pres~poly(age,2)*c.edu + partit + inter + close, family=binomial, data=elecc92)
summary(m8)
anova(m7,m8,test="Chisq")
waldtest(m7,m8,test="Chisq")
```

13.	Considereu la satisfacció amb les candidatures. La gent que no està satisfeta amb les candidatures té una menor incidència de vot? Canviaria la conclusió si el 'grau d'interès' en les eleccions no estigués inclòs en el model?

```{r}
m8 <- glm(pres~poly(age,2)*c.edu + partit + inter + sat, family=binomial, data=elecc92)
summary(m8)
anova(m7,m8,test="Chisq")
```

- Best model $\rightarrow$ **m7**

14.	Feu la diagnosi del vostre model final.

```{r}
# Diagnosi
model.final <- m7
scatterplot(rstudent(model.final)~cooks.distance(model.final)|elecc92$c.edu, id=list(n=3))
marginalModelPlots(model.final,id=list(method=abs(cooks.distance(model.final)),n=5)) 
residualPlots(model.final, layout=c(3, 2))
outlierTest(model.final)
influenceIndexPlot(model.final,id=list(vars=c("Cook", "Student","hat"),n=3))
influencePlot(model.final,id=list(n=0))

matplot(dfbetas(model.final),type='l')
abline(h=sqrt(4/(dim(elecc92)[1])),lty=3,col=6)
abline(h=-sqrt(4/(dim(elecc92)[1])),lty=3,col=6)
lines(sqrt(cooks.distance(model.final)),lwd=3,col=1)
#legend(locator(n=1),legend=c(names(as.data.frame(dfbetas(model.final))),"Cook D"), col=c(1:3,1), lty=c(3,3,3,1) )
```

15.	Empreu el vostre model final per predir el comportament d'un votant. Classifiqueu com a votant probable aquells individus amb probabilitat superior o igual a 0.5. Feu una taula de contingència amb el vot probable i el vot real i analitzeu-la. Quina és l'explicabilitat del model final?

```{r}
prob.vot <- model.final$fit
Boxplot(prob.vot~elecc92$pres)
pres.est <- ifelse(prob.vot<0.5,0,1)
(conf.matrix <- table(pres.est,elecc92$pres))
sum(diag(conf.matrix))/sum(conf.matrix)
```

Model naive:

```{r}
m0 <- glm(pres ~ 1, family=binomial, data=elecc92)
prob.vot <- m0$fit
pres.est <- ifelse(prob.vot<0.5,0,1)
(conf.matrix0 <- table(pres.est,elecc92$pres))
conf.matrix0[1,2]/sum(conf.matrix0)
```

16.	Calculeu el pseudo coeficient de determinació del model final i el coeficient de Naglekerke. Feu un goodness of fit test sobre el model final. Calculeu el goodness of fit emprant l'estadístic proposat per Hosmer-Lemershow.

$R^2$

```{r}
options(contrasts=c("contr.treatment","contr.treatment"))
model.final1 <- lrm(pres ~ poly(age,2) + c.edu + partit + inter, data=elecc92)
model.final1
summary(model.final)

D <- model.final$dev                      # Deviance final model
D0 <- model.final$null.dev                # Null deviance
n <- nrow(elecc92)                    

NagelkerkeR2(model.final)                                                       # R2 Nagelkerke
(1 - exp((D-D0)/n)) / (1-exp(-D0/n))                                            # R2 Nagelkerke by hand
1 - model.final$dev/model.final$null.dev                                        # R2 McFadden
1 - (logLik(model.final)/model.final$df.residual)/(logLik(m0)/(m0$df.residual)) # Another pseudo-R2
```

Estadístic de Hosmer-Lemershow:

```{r}
seque <- c(0,seq(0.2,0.95,by=0.05))
elecc92$fitgrup <- cut(fitted(model.final),breaks=seque)
cfitgrup <- table(elecc92$pres,elecc92$fitgrup);cfitgrup
csample <- tapply(elecc92$pres,elecc92$fitgrup,sum);csample
cmodel <- tapply(fitted(model.final),elecc92$fitgrup,sum);cmodel
XHL <- sum(((cmodel-csample)^2)/cmodel);XHL
dfXHL <- nlevels(elecc92$fitgrup) - 2
1 - pchisq(XHL,dfXHL)
```

17.	Determineu la capacitat predictiva mitjançant l'anàlisi de la corba ROC.
```{r}
dadesroc <- prediction(predict(model.final,type="response"),elecc92$pres)
par(mfrow=c(1,2))
performance(dadesroc,"auc",fpr.stop=0.05)
plot(performance(dadesroc,"err"))
plot(performance(dadesroc,"tpr","fpr"))
abline(0,1,lty=2)
#roc(predict(model.final,type="response"),factor(elecc92$pres))
```


18. Feu un calibration.plot
```{r}
# Predicted
pr <- predict(model.final,type='response')
q <- quantile(pr,seq(0,1,0.05))
x <- as.numeric(rowMeans(cbind(q[-1],q[-11])))
pr.cat <- cut(pr,br=q,include.lowest = TRUE)

# Observed with CI
Y <- matrix(ncol=3,nrow=nlevels(pr.cat))

plot(NA,xlim=0:1,ylim=0:1,xlab='Predicted',ylab='Observed')
abline(0,1,lty=2)

for(i in 1:nlevels(pr.cat)){
  e <- sum(elecc92$pres[pr.cat==levels(pr.cat)[i]])
  n <- sum(pr.cat==levels(pr.cat)[i])
  bt <- binom.test(e,n)
  Y[i,] <- as.numeric(c(bt$estimate,bt$conf.int))
  points(x[i],Y[i,1],pch=15,cex=1.1)
  segments(x[i],Y[i,2],x[i],Y[i,3],lwd=2)
}
```