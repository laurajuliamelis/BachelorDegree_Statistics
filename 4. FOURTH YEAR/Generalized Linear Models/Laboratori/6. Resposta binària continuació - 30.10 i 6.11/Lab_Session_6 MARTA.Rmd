---
title: "Lab Session 5"
author: "Lidia Montero, Josep Anton Sanchez & Jordi Cortes"
date: "October 2018"
output:
  html_document: default
---

## Prepare Dataset and load packages

```{r, warning=FALSE, message=FALSE}
load("Eleccions_92.RData")
options(contrasts=c("contr.treatment","contr.poly"))
library(car)
library(MASS)
#library(AER) no es fa servir
library(effects) #plotAllEffects
library(lmtest) #Waldtest li podem passar funcions lineals
library(FactoMineR) #catdes
library(rms)
library(fmsb)
library(ROCR) #corva ROC
library(AUC)
```

# Define response variable (pres) and factors properly. 

New variables will be created: they will be use further.

```{r}
### Punt 1
summary(elecc92)

elecc92$inter <- factor(elecc92$inter,levels=c("none","some","high"))
elecc92$close <- factor(elecc92$close,labels=c("Close-No","Close-Yes"))
elecc92$sat <- factor(elecc92$sat,labels=c("Sat-No","Sat-Yes"))
elecc92$vota <- factor(elecc92$pres,labels=c("Pres-No","Pres-Yes"))
elecc92$c.age <- cut(elecc92$age,breaks=c(16,29,39,59,91))
elecc92$ones <- rep(1,length(elecc92$pres))
elecc92$c.edu <- cut(elecc92$educ,breaks=c(-1,11,12,15,17))
elecc92$p <- factor(elecc92$p,levels=c('ind','weak','strong'))

elecc92$id <- NULL # Not use

summary(elecc92)
```

# Point 1: Exploratory Data Analysis

Categories are reasonably well balanced

```{r, fig.height=3.5}
par(mfrow=c(1,2),las=2)
barplot(table(elecc92$c.age))
barplot(table(elecc92$c.edu))
```

```{r, fig.height=6}
par(mfrow=c(1,2),las=1)
Boxplot(age~pres,data=elecc92,col=c(2,3))
Boxplot(educ~pres,data=elecc92,col=c(2,3))

par(mfrow=c(3,2),las=1)
plot(vota~inter,data=elecc92,col=c(2,3))
plot(vota~close,data=elecc92,col=c(2,3))
plot(vota~sat,data=elecc92,col=c(2,3))
plot(vota~inter,data=elecc92,col=c(2,3))
plot(vota~c.age,data=elecc92,col=c(2,3))
plot(vota~c.edu,data=elecc92,col=c(2,3))
```


# Feature Selection

```{r}
summary(elecc92)
catdes(elecc92,9)  # 9 is the index of variable vota
```

\pagebreak

# Point 2: Aggregated vs Desaggregated data for binary response models

Disaggregated data

```{r}
m1 <- glm(pres~age,data=elecc92,family=binomial)
summary(m1)

par(mfrow=c(2,2))
plot(m1)
```

Function to create an aggregated dataset using classes defined by age

```{r,echo=FALSE}
# Codi de la rutina
agregacio <- function(dfin, nve, formula1, formula2){
# Exemple crida: dfage <- agregacio(elecc92,1,as.formula(uns~age),as.formula(pres~age))
# Retorna dataframe: dfage amb age, m, ypos, yneg. 
#
# Formula1 ha de ser uns~var1+...+var_nve
# Formula2 ha de ser resposta~var1+...+var_nve.Resposta ha de ser num?rica.
# Requereix que dfin,data.frame d'entrada contingui una columna amb uns
# Retorna: dfout, data.frame amb var1 , ..., var_nve, m, ypos, yneg.
# Valid per nve arbitrari > 0

taulam <- xtabs(formula1,exclude=NULL,dfin,drop.unused.levels=TRUE);
taulap <- xtabs(formula2,exclude=NULL,dfin,drop.unused.levels=TRUE);

dfout <- as.data.frame(taulam);
dfaux <- as.data.frame(taulap);

names(dfout)[nve+1] <- "m";
names(dfaux)[nve+1] <- "ypos";
attach(dfaux);
dfout <- data.frame(dfout,ypos);
dfout$m <- as.integer(dfout$m)
dfout$yneg <- as.integer(dfout$m-dfout$ypos);
attach(dfout);
dfout <- dfout[m>0,]
}
```

# Aggregated data

In this case, it is possible to aggregate by a continous variable because it is discretized and the sample size is big enough

```{r}
dfage <- agregacio(elecc92,1,as.formula(ones~age),as.formula(pres~age))
summary(dfage)
dfage$age <- as.numeric(levels(dfage$age))[dfage$age]
head(dfage)
summary(dfage)
```

In the model, the coefficients are the same that those ones with dissagragated data, but not the deviance and degrees of freedom.

```{r}
m1a <- glm(cbind(ypos,yneg)~age,data=dfage,family=binomial)
summary(m1a)
```

# Goodness of fit

When disaggregated data is used then $m_i = 1$ and asymptotic theory does not apply, as a rule of thumb at a fully disaggregated level for data, a model is good if Deviance or Pearson $\chi^2$ statistics are similar to degrees of freedom of the model. Large values indicate a lack of fit of the model.

```{r}
1 - pchisq(m1a$dev,m1a$df.res)  # Aggregated data model
m1$dev;m1$df.res                # Disaggregated data
```


# Interpretation

The exponential of the coefficient represents the OR on the positive response for a 1-year increase.

```{r}
# Interpretacio efecte age en m1
cat('An increase of one year in age is associated with an increase of', round(exp(coef(m1)['age']),3), 'in the odds of positive response\n')    # Increment 1 any
cat('An increase of 10 years in age is associated with an increase of', round(10*exp(coef(m1)['age']),3), 'in the odds of positive response\n') # Increment 10 anys
```


Let's check the fit using a manual plot and also residual analysis methods available in package car. There is a non-linear relationship between age and the logodds of the positive response. 

By hand:

```{r}
par(mfrow=c(1,1))
dfage$olog <- log((dfage$ypos+0.5)/(dfage$yneg+0.5))    # logodds
plot(dfage$age,dfage$olog,pch=19)                       # points
points(dfage$age,m1a$linear.predictor,col=2,lwd=1.5)    # Linear relationship
lines(lowess(dfage$age,dfage$olog,f=0.5),col=3)         # high smooth        
lines(lowess(dfage$age,dfage$olog,f=0.75),col=4,lwd=2)  # medium smooth        
lines(lowess(dfage$age,dfage$olog,f=1.0),col=5)         # low smooth        
```

Another equivalent plot done with the function *scatterplot* of the *car* package:

```{r}
scatterplot(olog~age,dfage,col=1,regLine=list(col=4),smooth=list(col.smooth=3,col.var=3))
```

Plot effects using the function *allEffects*:

```{r}
plot(allEffects(m1),ask=FALSE)
```

```{r warning=FALSE}
residualPlots(m1a, layout=c(1, 2))                                  # Pearson residuals versus predictors
marginalModelPlots(m1a,id=list(method=abs(cooks.distance(m1)),n=5)) 
```

\pagebreak

# Point 3: Exercise

3.	Ajusteu un model de regressi? log?stica amb predictor lineal els termes d'ordre 1 i 2 de l'EDAT (Models  M1-2, M1-3, variants de M1) (els ordres no lineals obteniu-los sempre respecte la tend?ncia central de la variable o empreu la comanda poly(EDAT,k)). 

Dos metodes: amb la funcio $I$ o amb la funcio $poly$. Es centra per a que tingui sentit el valor nul.


```{r}
m1.1 <-  glm(pres ~ age,                                 data=elecc92,family=binomial)  # Relaci? lineal
m1.2 <-  glm(pres ~ age + I((age-42)^2),                 data=elecc92,family=binomial)  # Relaci? quadr?tica
m1.3 <-  glm(pres ~ age + I((age-42)^2) + I((age-42)^3), data=elecc92,family=binomial)  # Relaci? c?bica
m1.2p <- glm(pres ~ poly(age,2,raw=TRUE),                data=elecc92,family=binomial)  # Relaci? quadr?tica
m1.3p <- glm(pres ~ poly(age,3),                         data=elecc92,family=binomial)  # Relaci? c?bica
```

a.	Contrasteu formalment la significaci? del terme d'ordre 3 de l'edat: segons l'estad?stic de Wald i segons el contrast de la devian?a.

```{r}
anova(m1.2,m1.3,test="Chisq")              # Deviance
anova(m1.2p,m1.3p,test="Chisq")            # Deviance --> Equivalent to previous


waldtest(m1.2,m1.3,test="Chisq")           # Wald
linearHypothesis(m1.3p,"poly(age, 3)3=0")  # Wald --> Equivalent to previous
```

b.	Contrasteu formalment la significaci? del terme d'ordre 2 de l'edat: segons l'estad?stic de Wald i segons el contrast de la devian?a. 
```{r}
anova(m1,m1.2,test="Chisq")      # Deviance
waldtest(m1,m1.2,test="Chisq")   # Wald
```

CONTINUACI? A PARTIR D'AQU?!!!!

c.	Useu sobre el conjunt de dades desagregat la comanda: marginalModelPlots() en m1 i model triat.
```{r warnings=FALSE}
plot(allEffects(m1.2p),ask=FALSE)

par(mfrow=c(2,2))
marginalModelPlots(m1.2p,id=list(method=abs(cooks.distance(m1.2p)),n=5)) 
summary(m1.2p)
```

d.	Feu una diagnosi est?ndard del model desagregat triat (m1): residualPlots()
```{r}
residualPlots(m1.2p, layout=c(1, 2))
```

4.	Considereu l'agrupaci? de l'EDAT en categories <30, 30-39, 40-59, 60+. Diem-li Model (M2).  Tornarem a calcular el model m2 amb dades desagregades (i si en teniu ganes m2a amb dades agregades).
a.	Feu una diagnosi est?ndard del model desagregat (m2c): residualPlots(m2c)
b.	Representeu el logits emp?rics/ajustats en funci? de l'EDAT Categoritzada en les dades agregades (diagnosi artesanal). Pistes: Us ho podeu estalviar examinant atentament el sumari del model agregat m2a.
```{r warnings=FALSE}
m1c <- glm(pres~c.age,data=elecc92,family=binomial)
summary(m1c)
exp(coef(m1c)['c.age(39,59]'])          # OR for this category in respect to reference
residualPlots(m1c , layout=c(1, 2))
marginalModelPlots(m1c,id=list(method=abs(cooks.distance(m1c)),n=5)) 
```

5.	Quin tractament us sembla m?s adient per la variable EDAT: com a covariable (fins a quin terme d'ordre) o com a factor. Justifiqueu estad?sticament la resposta.

Els models **No s?n niuats**, per tant no podem usar la devian?a.

```{r}
AIC(m1,m1.2p,m1c)
BIC(m1,m1.2p,m1c)
```
ml.2p millor model (tant el AIC com el BIC ?s m?s baix)
ml.2p: model que afegeix el terme quadr?tic

6.	Ara estudiarem la introducci? de la variable EDUCACI? en el model que ja cont? l'EDAT (en el seu millor tractament). Per comen?ar es treballar? amb l'EDUCACI? com a covariant.
a.	Afegiu un terme lineal d'EDUCACI? en el millor model anterior amb l'EDAT.

```{r}
m3n.1  <- glm(pres ~ poly(age,2) + educ, data=elecc92,family=binomial)
#edat de forma polynomica de grau dos
#educ num?rica
summary(m3n.1)
```
La educaci? s'ha de incloure en el model de forma signidicativa
educ=0.25289 --> INTERPRETACI?: per cada any m?s d'educaci? aconseguim incrementar el logodds en 0.25 (escala logodds log(pi/(1-pi)))

Lo habitual es treballar en l'escala del odds pi/(1-pi). canviem d'una escala a l'altre fent exp(0.25289). interpretaci? en termes multiplicatius respecte els odds-ratio


b.	Interpreteu el coeficient estimat en termes dels logodds i odds. 
```{r}
b_edu <-  round(coef(m3n.1)['educ'],3) # Increment en logodd
OR_edu <- round(exp(b_edu),3)          # Increment en odds --> OR
cat('An increase of 1 year in the education is associated with an increase of',b_edu,'in the logodds\n')
cat('An increase of 1 year in the education is associated with an increase of',OR_edu,'in the odds\n')
```
1.288 = exp(0.253) ODD-RATIO

c.	Contrasteu la hip?tesi que l'efecte de EDUCACI? ?s lineal mitjan?ant la introducci? d'un terme d'ordre 2 en el model. I el terme d'ordre 3, ?s significatiu? Pareu a l'ordre 3.

S'observa que tant el terme d'ordre 2 com el terme d'ordre 3 s?n significatius.

```{r}
m3n.2  <- glm(pres ~ poly(age,2) + poly(educ,2),data=elecc92,family=binomial)
m3n.3  <- glm(pres ~ poly(age,2) + poly(educ,3),data=elecc92,family=binomial)

anova(m3n.1,m3n.2,test="Chisq")  # Test de la devian?a
anova(m3n.2,m3n.3,test="Chisq")  # Test de la devian?a
```

 2469.9   2463.1 ha baixat 6.8348 no ?s fruit del atzar. ?s p-valor ?s < 0.05 per tant els models s?n diferents i ens quedem amb el m?s complicat.
 
 En el segon cas, veiem que cal mantenir el terme cubic perque aconseguim reduir la devian?a residual en 23.85 unitats.
 
 Fins a grau 5 potser que ens sortis significatiu (podr?em explorar).
 
 Els anys d'educaci? dintre del model en quin grau ens quedarien? Grau 3.

d.	Trieu el millor model que empra l'EDAT i la covariant EDUCACI?: li direm (m3n). No cal treballar amb la versi? agregada tret que vulgueu fer diagnosi artesanal.

```{r}
m3n <- m3n.3 #model c?bic
```

e.	Useu les eines standard d'an?lisi de residus: marginalModelPlots() i residualPlots().
```{r warnings=FALSE}
residualPlots(m3n , layout=c(1, 3))
marginalModelPlots(m3n,id=list(method=abs(cooks.distance(m3n)),n=5)) 
```
Degut a que les dades estan desagregades la validaci? no es adecuada amb aquest tipus de gr?fics.
El marginalmodelplot: linea vermella=predicci? del model. Estem intentant veure una certa correspondencia. Tant en el cas de l'edat com en el cas de l'educaci? sembla que l'ajust ?s afinat.

Tamb? ens podriem plantejar que l'edat entres categoritzada.


7.	Considereu una agrupaci? dels anys d'educaci? (EDUCACI? Categoritzada) en 4 grups: <12, 12, 13-15, 16+. Estimeu el model de regressi? log?stica amb els termes i tractament adient de  l'edat i el factor EDUCACI?. Quina ?s la millor manera de tractar els anys d'educaci?? Li direm (M4).
i.	Assageu rectes de l'edat amb pendents id?ntics per cada categor?a d'EDUCACIO
    4 grups amb pendents iguals. Tantes alpha_i com dummies creariem
    log(pi/(1-pi)) = beta0 + beta1AGE + alpha_i*EDUC_i
    
ii.	Assageu rectes de l'edat amb pendents diferents per cada categor?a d'EDUCACIO
    4 grups amb pendents diferents.
    log(pi/(1-pi)) = beta0 + beta1AGE + alpha_i*EDUC_i + landa_iAGE:EDUC
    
iii.Assageu par?boles de l'edat amb id?ntica corbatura per cada categor?a d'EDUCACIO 
    la corvatura d'una par?bola ?s el terme quadr?tic
    4 grups amb la mateixa corbatura --> AGE=>poly(AGE,2)
    
iv.	Assageu par?boles de l'edat amb diferent corbatura per cada categor?a d'EDUCACIO
    4 grups amb la mateixa corbatura --> afegim interacci?
    
v.	Estrictament per infer?ncia, quin us sembla el tractament m?s apropiat.
L'?ltim ?s el m?s complicat.

```{r}
m4.1  <-glm(pres ~ age + c.edu,        data=elecc92,family=binomial) # Model i) #gastem tres gr.ll respecte al model lineal
m4.2  <-glm(pres ~ age * c.edu,        data=elecc92,family=binomial) # Model ii)   
m4.3  <-glm(pres ~ poly(age,2) + c.edu,data=elecc92,family=binomial) # Model iii) 
m4.4  <-glm(pres ~ poly(age,2) * c.edu,data=elecc92,family=binomial) # Model iv) #gastem 6 gr.ll. nomes pel fet de incloure la interraci? tenim 6 paramentres m?s


anova(m4.1,m4.2,test="Chisq")    # El terme d'interacci? sembla necessari
#les pendents de les rectes no s?n paral.leles

anova(m4.1,m4.3,test="Chisq")    # El terme quadr?tic de l'edat sembla necessari
# anova(m4.2,m4.3,test="Chisq")  # Incorrecte --> No es poden comparar perqu? no s?n niuats

anova(m4.3,m4.4,test="Chisq")    # Ambdos termes s?n nessaris
anova(m4.2,m4.4,test="Chisq")    # Ambdos termes s?n nessaris
```

Effects. Probability of positive response is higher in those individuals with more years of education. The trend is poitive along years in individuals with less eduaction: older implies more chances to vote. On the other hand, older persons with higher education (category from 15 to 17 years of eduaction) have lower probability to vote. 

```{r}
plot(allEffects(m4.4),ask=FALSE)
```

```{r warnings=FALSE}
residualPlots(m4.4 , layout=c(1, 3)) #ajuden poc a poder validar el model
marginalModelPlots(m4.4,id=list(method=abs(cooks.distance(m4.4)),n=5),layout=c(2,2)) 
scatterplot(log((pres+0.05)/(1-pres+0.05)) ~ age|c.edu,smooth=TRUE,data=elecc92) #predicci? de cda un dels grups # ,col=c(0,0,0,1) --> To see only one variable
#linia blava discontinua i l?nea rosa discontinua no estan sobreposades perque vol dir que no en tenim prou amb el model lineal
```





8.	Quina ?s la millor manera de tractar els anys d'educaci?, un cop l'EDAT ja ha estat incorporada en el model?

Comparing models by AIC and BIC
According to BIC, it is better not to use the term of interaction, but according to AIC and also with deviance test it is a better option to kae it into account.

```{r warnings=FALSE}
BIC(m3n,m4.1,m4.2,m4.3,m4.4)
AIC(m3n,m4.1,m4.2,m4.3,m4.4)
```
df=p (normalment df=n-p). Segons AIC aix? val la pena introduir aquesta interacci? entre la parabola i la variable categorica.
Segons BIC el que contempla que l'edat sigui cuadratica pero no hi hagi diferent corbatura per cada un dels grups.
BIC ?s m?s estricte. Els termes que queden al BIC son significatius al 0.5%.

# Interpretation of the selected model

```{r warnings=FALSE}
summary(m4.4)
```
Hem gastat 12 gr.ll

9.	Afegir al model les prefer?ncies partidistes. Analitzar els coeficients estimats i suggerir com es podria recodificar aquesta variable per simplificar la interpretaci? del model i estalviar un quants graus de llibertat (heu de veure que amb m?xim 3 categories ?s suficient). Reajustar el model i reinterpretar els coeficients de la variable codificada.

Crear nova variable:

```{r}
elecc92$party <- as.factor(paste(elecc92$p,elecc92$arty))
summary(elecc92)
m6.1 <- glm(pres ~ poly(age,2)*c.edu + party, family=binomial, data=elecc92)
summary(m6.1)

anova(m4.4, m6.1, test='Chisq')
plot(allEffects(m6.1))
```

- New categorization:
    - *ind dem* or *ind rep* or *weak dem* or *weak rep* $\rightarrow$ *weak*
    - *strong dem* or *strong rep* $\rightarrow$ *strong*
    - *ind ind* $\rightarrow$ *ind*

```{r}
# Agrupacio de categories
elecc92$partit <- rep("weak",length(elecc92$party))
elecc92$partit[elecc92$party=="strong rep" | elecc92$party=="strong dem"] <- "strong"
elecc92$partit[elecc92$party=="ind ind"] <- "ind"
elecc92$partit <- factor(elecc92$partit,levels=c("ind","weak","strong"))

m6.2 <- glm(pres ~ poly(age,2)*c.edu + partit, family=binomial, data=elecc92)
summary(m6.2)

anova(m6.2,m6.1,test="Chisq")

plot(allEffects(m6.2),ask=FALSE)
m6 <- m6.2
```

10.	Introdu?u la variable *grau d'inter?s* en les eleccions en el model. Contrasteu la significaci? del seu efecte principal emprant: test de Wald (si el paquet estad?stic us ho permet) i el test de la devian?a. Afirmar?eu que la principal ra? per la que la gent jove vota menys ?s que no estan interessats en les eleccions?

```{r}
elecc92$inter <- ordered(elecc92$inter,levels=c("none","some","high"))
m7 <- glm(pres~poly(age,2)*c.edu + partit + inter, family=binomial, data=elecc92)
summary(m7)

plot(allEffects(m7),ask=F)
anova(m6,m7,test="Chi")      # Deviance test
anova(m6,m7,test="Cp")       # Mallows' Cp statistic is closely related to AIC: AIC(m6,m7)
waldtest(m6,m7,test='Chisq') # Wald test 
```

11.	Introdu?u en el model un terme d'interacci? entre el 'grau d'inter?s' i les 'prefer?ncies partidistes'. Contrasteu la significaci? de la interacci? mitjan?ant el test de devian?a. Expliqueu detalladament, si hi ho trobeu evid?ncia, com funciona la interacci?.

```{r}
m8 <- glm(pres~poly(age,2)*c.edu + partit*inter, family=binomial, data=elecc92)
summary(m8)
anova(m7,m8,test="Chisq")
```

12.	Hi ha alguna evid?ncia que, despr?s d'introduir el factor de 'proximitat entre els candidats' en el model TREBALLAT FINS EL MOMENT (EDAT, EDUCACIO, PREFER?NCIES PARTIDISTES, GRAU D'INTER?S), les persones que creuen que les eleccions s?n ajustades tinguin una major incid?ncia de vot?

```{r}
m8 <- glm(pres~poly(age,2)*c.edu + partit + inter + close, family=binomial, data=elecc92)
summary(m8)
anova(m7,m8,test="Chisq")
waldtest(m7,m8,test="Chisq")
```

13.	Considereu la satisfacci? amb les candidatures. La gent que no est? satisfeta amb les candidatures t? una menor incid?ncia de vot? Canviaria la conclusi? si el 'grau d'inter?s' en les eleccions no estigu?s incl?s en el model?

```{r}
m8 <- glm(pres~poly(age,2)*c.edu + partit + inter + sat, family=binomial, data=elecc92)
summary(m8)
anova(m7,m8,test="Chisq")
```

- Best model $\rightarrow$ **m7**

14.	Feu la diagnosi del vostre model final.

```{r}
# Diagnosi
model.final <- m7
scatterplot(rstudent(model.final)~cooks.distance(model.final)|elecc92$c.edu, id=list(n=3))
marginalModelPlots(model.final,id=list(method=abs(cooks.distance(model.final)),n=5)) 
residualPlots(model.final, layout=c(3, 2))
outlierTest(model.final)
influenceIndexPlot(model.final,id=list(vars=c("Cook", "Student","hat"),n=3))
influencePlot(model.final,id=list(n=0))

matplot(dfbetas(model.final),type='l')
abline(h=sqrt(4/(dim(elecc92)[1])),lty=3,col=6)
abline(h=-sqrt(4/(dim(elecc92)[1])),lty=3,col=6)
lines(sqrt(cooks.distance(model.final)),lwd=3,col=1)
#legend(locator(n=1),legend=c(names(as.data.frame(dfbetas(model.final))),"Cook D"), col=c(1:3,1), lty=c(3,3,3,1) )
```

15.	Empreu el vostre model final per predir el comportament d'un votant. Classifiqueu com a votant probable aquells individus amb probabilitat superior o igual a 0.5. Feu una taula de conting?ncia amb el vot probable i el vot real i analitzeu-la. Quina ?s l'explicabilitat del model final?

```{r}
prob.vot <- model.final$fit
Boxplot(prob.vot~elecc92$pres)
pres.est <- ifelse(prob.vot<0.5,0,1)
(conf.matrix <- table(pres.est,elecc92$pres)) #matriu de confusi?
sum(diag(conf.matrix))/sum(conf.matrix) #percentatge de ben classificats
```

Model naive:

```{r}
m0 <- glm(pres ~ 1, family=binomial, data=elecc92)
prob.vot <- m0$fit
pres.est <- ifelse(prob.vot<0.5,0,1)
(conf.matrix0 <- table(pres.est,elecc92$pres))
conf.matrix0[1,2]/sum(conf.matrix0)
```
Respecte el model null, el nostre model millor? la predicci? en 76%-69%

16.	Calculeu el pseudo coeficient de determinaci? del model final i el coeficient de Naglekerke. Feu un goodness of fit test sobre el model final. Calculeu el goodness of fit emprant l'estad?stic proposat per Hosmer-Lemershow.

$R^2$

```{r}
model.final1 <- lrm(pres ~ poly(age,2) + c.edu + partit + inter, data=elecc92)
model.final1
summary(model.final)

D <- model.final$dev                      # Deviance final model
D0 <- model.final$null.dev                # Null deviance
n <- nrow(elecc92)                    

NagelkerkeR2(model.final)                                                       # R2 Nagelkerke
(1 - exp((D-D0)/n)) / (1-exp(-D0/n))                                            # R2 Nagelkerke by hand
1 - model.final$dev/model.final$null.dev                                        # R2 McFadden
1 - (logLik(model.final)/model.final$df.residual)/(logLik(m0)/(m0$df.residual)) # Another pseudo-R2
```

Estad?stic de Hosmer-Lemershow:

```{r}
seque <- c(0,seq(0.2,0.95,by=0.05))
elecc92$fitgrup <- cut(fitted(model.final),breaks=seque)
cfitgrup <- table(elecc92$pres,elecc92$fitgrup);cfitgrup
csample <- tapply(elecc92$pres,elecc92$fitgrup,sum);csample
cmodel <- tapply(fitted(model.final),elecc92$fitgrup,sum);cmodel
XHL <- sum(((cmodel-csample)^2)/cmodel);XHL
dfXHL <- nlevels(elecc92$fitgrup) - 2
1 - pchisq(XHL,dfXHL)
```

17.	Determineu la capacitat predictiva mitjan?ant l'an?lisi de la corba ROC.
```{r}
dadesroc <- prediction(predict(model.final,type="response"),elecc92$pres)
par(mfrow=c(1,2))
performance(dadesroc,"auc",fpr.stop=0.05)
plot(performance(dadesroc,"err"))
plot(performance(dadesroc,"tpr","fpr"))
abline(0,1,lty=2)
#roc(predict(model.final,type="response"),factor(elecc92$pres))
```

