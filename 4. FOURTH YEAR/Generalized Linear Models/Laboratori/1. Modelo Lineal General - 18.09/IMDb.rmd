---
title: "Sesión 1: Model Lineal General, caso IMDb"
author: "MLGz"
date: "18 de septiembre de 2018"
output: html_document
---

```{r setup, include=FALSE}
#install.packages("knitr")
#install.packages("car")
#install.packages("effects")
#install.packages("emmeans")
#install.packages("ggplot")
#install.packages("ggplot2")
#install.packages("multcompView")
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(effects)
library(emmeans)
```

# IMDb data

El conjunto de datos  contiene información de 322 películas de cine de USA de la última década. Los datos se han recogido de la web www.imdb.com e incluyen la siguiente información:

- movie_title:	Título de la película

- gross:	Recaudación total (millones de $)

- budget:	Presupuesto	(millones de $)

- duration:	Duración (minutos)	

- title_year:	Año de estreno	

- actor1_fl:	Popularidad del primer actor (número de "Likes" en Facebook)	

- actor2_fl:	Popularidad del segundo actor (número de "Likes" en Facebook)	

- actor3_fl:	Popularidad del tercer actor (número de "Likes" en Facebook)	

- cast_fl:	Popularidad total del casting (número de "Likes" en Facebook)	

- faces_poster:	Número de caras que aparecen en el póster	

- Genre: 	Género de la película (Comedy, Drama, Action, Horror)

Se pretende explorar las relaciones entre las variables recogidas y la recaudación de la película. 

```{r}
data=read.csv2("IMDb.csv")
summary(data)
row.names(data)=data[,1]
data=data[,-1]
head(data)
```
**COMENTARIS:**
row.names(data)=data[,1] per prescindir de la codificació de cada nm i quedarnos nomes amb la etiqueta del titul de la película.


## Regresión Lineal Múltiple (sólo covariables)

**COMENTARIS:**
Descartem en aquest apartat la variable gènere (per ser string) i l'any de la peli (perquè no sembla raonable que l'haguem d'introduir com a numèrica per explicar el model) i per a la RLM només hem de tenir variables quantitatives.

Així doncs, treballarem amb l'any més endavant com a categòrica i fixarem períodes. 

```{r}
pairs(data[,c(1:3,5:10)])
```

**COMENTARIS:**
A sobre veiem un MATRIXPLOT, podem veure les relacions (regresións) lineals de totes les variables que hem deixat. 

REVISEM QUE LES ESCALES SIGUIN RAONABLES:El primer que cal observar és que tant la recaptació com el pressupost tenen una escala que és en dolars que fan que l'escala sigui molt gran. 

Quan els valors son tant grans les betas del model la variància residual sera de 10^-13, fa que l'estimació dels coeficients sigui inestable. També passa si l'escala es molt petita (molts decimals)

A continuació veiem al gràfics que l'escala esta sobre 10^+8 i 3^+8.


```{r}
pairs(~gross+budget+duration,data)
```
El gràfic anterior ens permet veure si hi ha relació i si la relació es positiva o negativa. També, ens ajuda a diagnosticar si hi haurá multicolinealitat.

Més concretament, entre gross-budget i gross-dration sembla que a més pressupost més recaptació pero conforme aumenta el gross aumenta la variabilitat. El mateix passa amb la duració. Això, com ja sabem es motiu de heteroscedasticitat. (mirem el summary de: summary(mod<-lm(gross~duration+budget,data))).


Així doncs, dividim per un milió (10^6) les dues variables de es que parlavem. Ara estan en milions de dolars i no en dolars.

```{r}
data$gross=data$gross/1e6
data$budget=data$budget/1e6
data$year=factor(cut(data$title_year,c(0,2008,2012,2017)),labels=c("2006-2008","2009-2012","2013-2016"))
summary(data)
table(data$title_year,data$year)
```



```{r}
summary(mod<-lm(gross~duration+budget,data))
summary(modb<-glm(gross~duration+budget,data,family=gaussian))

```

*SORTIDA DEL PRIMER OUTPUT:*
HO: beta(i)=0
H1; beta(i)!=0

Model teòric: Y=Xbeta+errors
Model ajustat: Y=Xbeta_barret+residus

La durada té influencia en la recaptació? 
Si, rebutjem la hip nul.la degut a ca el pvalor associada al t valor és significatiu.
Malgrat aixó, al no tractar-se d'un disseny experimental sinó de dades obsrvacionals, no podem parlar de causalitat. Només de que hi ha relació.

En la darrera línia observem una comparació entre el model bo i el model ajustat, com que el p valor és menor a 0.05, diem que el model és significatiu. 

*SORTIDA DEL SEGON OUTPUT:*
glm : per a models lineals generalitats. a més de les variables, li hem d'indicar la familia. Dient que la familia es gaussiaa, estem indicant que la var y segueix una nomal.

Ara apareix la deviança i els residus de la devianá pero no el Rquadrat ni el Rquadrat ajustat. 

Dispersion parameter for gaussian family taken to be 4806.642 és la variància residual. OBSERVAR que en l'apartat anterior tenim el "Residual standard error: 69.33", que és el mateix!!

_RESIDUAL DEVIANÇA_:

RSS: sum(Y_i - mu_barret_i)^2

DF (graus de ll): N-P = 322-3=319
sigma_barret^2 = RSS/(N-P)

_NULL DIAVIANÇA_:

sum(Y_i - Y_guió_i)^2
DF: N-1
var_barret (Y_i) = sigma_barret^2= [sum(Y_i - Y_guió_i)^2]/N-1

Veiem que reduint una mica els paràmetres(de 321 a 319) la deviança es molt menor. Si a un model li afegim una variable la deviaça hauria de baixar, si no baixa, cal descartar el paràmetre que s'ha agefit. 



```{r}
par(mfrow=c(2,2))
plot(mod)
par(mfrow=c(1,1))
```

Aquest son els plots de validació:
1. Residus enfront de prediccions Per veure la linealitat.
2. Plot de normalitat. Per veure la normalitat
3. Scale location: arrel quadrada del primer amb un ajust suau.: Per veure si hi ha variancia constant. 
4. Residual vs leverage. PEr veure les observacions més influents. (o si hi ha una variable que sigui influient)

En el primer plot veiem molt clarametn que hi ha heteroscedasticitat. I amb la tercera confirmam que conforme augmenta la predicció, augemta la variança (variabilitat).

Així, el model no queda validat, i cal aplicar logaritmes.


**TRANFORMACIÓ LOGARÍTMICA:**
```{r}
data$lngross=log(data$gross)
data$lnbudget=log(data$budget)

pairs(~lngross+duration+lnbudget,data)

```

Treballarem amb el logarítmes. Ja no queda clar 'efecte trompeta que veiem abans. La variancia sembla mes constant.

Ajustem el model nou:

```{r}
summary(mod<-lm(lngross~duration+lnbudget,data))
summary(modb<-glm(lngross~duration+lnbudget,data,family=gaussian))

```

En el primer model veiem els tres parametres significatius.

La variància ja no es comparable amb l'anterior, ara hemcanviat l'escala.

El r^2 abans era 0.50 i ara 0.46, això vol dir que aquest model es pitjor? Que explica menys la variabilitat de la resposta?

No, NO son comparables perquè hem canviat l'escala de la resposta. 

Podem dir que la variabilitat está exlicada en u 46%. 

El AIC y la deviança del segon sumarytambpoc son comparables si canviem l'escala de la var resposta.



**ANOVA**
```{r}
anova(mod)
Anova(mod,type=3)
```

Hi ha una variabilitat total que la dividim en sumes de quadrats associades a les diferents variables que tenim i obtenim un valor F i uns pvalors associats. 

Anova (amb majúscula del paquet car) és el mètode anova pero amb el tipus:3.

Veiem que no coincideixen, hi ha diferències.  

Mètode anova d'un model (làsic) tenim la taula de la anova sequencial, ja que els pvalors ens estan comparant el model en que no hi ha res amb el model que te la durada, el segonpvalor hem compara el model amb la durada amb el model am la durada i el lnbudget, i així successivament. Només que escrivim les var en un ordre diferent, els pvalors seran diferents perque els models q comparara ja no seran iguals


El Mètode Anova, es el que es diu marginal o ---. Compara el model complet (amb totes les vars) amb el model sense la variable duration (pel cas del pvalor associat a la variable duration). Si es significatiu, significa que la variable ha d'estar dintre del model.

Type= 2 o type=3, té a veure quan hi ha interaccions. Amb el tipus dos inclou les interaccions encara que elimini la variable. 

```{r}
par(mfrow=c(2,2))
plot(mod)
par(mfrow=c(1,1))
```

La normalitat és indiscutible. La variança sembla constant perque veiem una variabilitat constant, no depen de les prediccions. Els residus tamb son propers a 0, encara que si hi ha algun nivels separats però no molts. 

**NOUS PLOTS:**
```{r}
residualPlots(mod)
```
El 3er es el mateix que abans (el primer d'abans): residus enfront a les prediccions. Però els dos primers son l'enfrontament dels residus ambcada una de les variables.

Ve acompanyart d'un test, que em permet veure si hi ha curvatura. Per saber si cal introduir les variables al quadrat.

**TEST DE NORMALITA:**
```{r}
shapiro.test(resid(mod))
shapiro.test(rstudent(mod))
par(mfrow=c(1,2))
qqPlot(resid(mod))
qqPlot(rstudent(mod))
par(mfrow=c(1,1))
```

El test ens dona un estadistic i un pvalor normal tant per als residus normals (0.33) com per als residus estudentitzats(0.34). Això ens permet assegurar la normalitat dels residus. 

Residus estandaritzats: amb valors atípics és molt gran (s'infla)

Residus estudentitzats: a cada observacio li resto la prediccio i divideixo per la desv estandard eliminant la obs atípica. 

Amb el qq plot podem introduir les regions de confianza i aixi la normalitat queda molt mes validad. 

```{r}
influencePlot(mod)
```

Aques plot es igual que el quart plot de la funcio plot(), combina la desv estandard amb el leverage. Quan les boles son grans, significa que tenen la dist de cook mes gran (son influents). Si les suprimim tendrem una estimació mes robusta.

Boyhood te una distancia de cook molt petita (esta molt ben predita, estimada) tot i que el leverage es molt alt. això és, que està mot allunyada, però no produeix palancament i per tant no em canvia la pendent de la recta de regressió (no és influent)

El leverage no depen de la resposta, es una funcio de la matriu de disseny.

Això ho podem veure també amb la taula de sota el gràfic, on apareixen les dades influents (distancia de cook gran o un leverage(hat) gran). 

Residus: residu positiu, s'ha recaptat mes de lo que indicaba la prediccio (residu=observat-predit)

```{r}
outlierTest(mod)
```


Nomes ens ho fa per a les que tenguin un residu +-3 (outliers)

Lillte children té un residu (error standard) mes gran que el valor absolut de 2

Corecció de Bonferroni(0.25): tot i que sigui un -3.39, es un valor raonable. Pot ser s'ha produit per atzar, i realment no és un atípic. 

**PACKAGE EFFECTS:**
```{r}
plot(allEffects(mod))
```

Ens agafa del model totes les interaccions. Veiem la recta de regresió i la regió de confiança.

Ens ajuda a interpretar, i saber exactament com es mou la resposta en funció del valor de les vars explicatives

Les linies d'abaix, en el eix x, son les dades de la bbdd. És el scope, l'abast, i podem veure on s troben la majoria de les observacions. Cada línia és una observació. 


**PREDICCIONS PER A UNA PELÍCULA:**
```{r}
pr<-predict(mod,newdata=data.frame(lnbudget=log(20),duration=90,year="2013-2016",director_fl=0,actor1_fl=0,actor2_fl=0,cast_fl=0,faces_poster=1,Genre="Horror"),interval="confidence")
exp(pr)
pr2<-predict(mod,newdata=data.frame(lnbudget=log(20),duration=90,year="2013-2016",director_fl=0,actor1_fl=0,actor2_fl=0,cast_fl=0,faces_poster=1,Genre="Horror"),interval="prediction")
exp(pr2)
```

Predict em dona  predicció amb un interval de confiança, el resultat es amb milions de dolars perquè ja li hem aplicat la exponencial (exp(pr)).

Interval=confidence: en promig podem garantit 38 milions, Fem la pedicció per al valor esperat. 

Interval=prediction: Volem predir una película en concret, agafem un individu, per això l'interval és molt més incert. 


## Análisis de la varianza (sólo factores)

```{r}
Boxplot(lngross~Genre,data)
Boxplot(lngross~year,data)
```
Ja no tenim diagrames de punts, veiem la distribució de la recaptació segons quin sigui el gènere de la película. Sembla que las de acció recaten mes q la resta, en quant a les altes no ho podem saber. Veiem dos atípics. 

Quan ho feim per anys, veiem que sembla que no hi ha diferència entre la recaptacio no te a veure amb el període.


Per tant, ens centrem en el génere. La varable està codificada com un factor, stà codificada numèricament. 


```{r}
summary(mod1<-lm(lngross~Genre,data))
```
Interpretació del model ajustat:

Interpretem el 4.89 com a (si el test es tipus treatment) és el valor esperat del logaritme de la recaptació si la película es d'acció. (el valor esperat de la var resposta quan el genere es el de referencia, la categoria base)

El -0.74 ees la diferencia entre la categoria base i la acual, es a dir: quan vulgui buscar la recaptació d'una comedia haure de fer 4.9-0.7. Com que l'intercept es significtiu, significa ue l'acció és diferent a la resta de gèneres. 

```{r}
Anova(mod1,type=3)
```
Per decidir si la variable es significativa. 

Variables dummy. 

```{r}
options(contrasts=c("contr.sum","contr.poly"))
contrasts(data$Genre)
summary(mod1b<-lm(lngross~Genre,data))
options(contrasts=c("contr.helmert","contr.poly"))
contrasts(data$Genre)
summary(mod1c<-lm(lngross~Genre,data))
options(contrasts=c("contr.treatment","contr.poly"))
contrasts(data$Genre)
summary(mod1)
```
Contastos que treballarem: baseline (vcategoria base- treatment) o suma 0(promig- contr.sum).


```{r}
par(mfrow=c(2,2))
plot(mod1)
par(mfrow=c(1,1))
```
```{r}
leveneTest(mod1)
residualPlots(mod1)
```
Ara, les caixes son els residus segons el génere. Per validar el model cal que les caixes estiguin alineades i que tinguin la mateixa amplada. 

Validació (com abans):
```{r}
shapiro.test(resid(mod1))
shapiro.test(rstudent(mod1))
par(mfrow=c(1,2))
qqPlot(resid(mod1))
qqPlot(rstudent(mod1))
par(mfrow=c(1,1))
```


```{r}
plot(allEffects(mod1))
```
Valor esperat de cada gènere amb l'interval de confiança (en rosa). 


```{r}
(emmod1<-emmeans(mod1,specs="Genre"))
```

```{r}
plot(emmod1)
```
Plot equivalent al dels ALLEFECTS.

```{r}
pairs(emmod1)
```
```{r}
cld(emmod1)
```

**PREDICCIÓ:**
```{r}
pr<-predict(mod1,newdata=data.frame(lnbudget=log(20),duration=90,year="2013-2016",director_fl=0,actor1_fl=0,actor2_fl=0,cast_fl=0,faces_poster=1,Genre="Horror"),interval="confidence")
exp(pr)
pr2<-predict(mod1,newdata=data.frame(lnbudget=log(20),duration=90,year="2013-2016",director_fl=0,actor1_fl=0,actor2_fl=0,cast_fl=0,faces_poster=1,Genre="Horror"),interval="prediction")
exp(pr2)
```

## Modelo Lineal General (factores y covariables)

Ara partim de la idea de: fes l'anàlisis nomes amb els factors(variables categòriques-year y genere- y les covariables- les numèriques), sense modificar l'escala i sense considerar interaccions.

**SELECCIÓ DE VARIABLES:**

1. Mecanismes:
    FORWARD: Y ~ 1 -> afegim (una variable i anem afegin allo q es significatiu).
    BAKWARD: Y ~ . -> treiem (ajustem el model complet (totes les vars) i anem traient tot allò no significatiu.)ç
    * Es preferible el Forward si el nom de variables és gran. Els dos ens poden donar models vàlids però diferents.
    STEPWISE:  Y ~ . & Y ~ 1 -> treiem o afegim. És el mecanisme més preferible dels tres. En cada pas podem triar afegir o treure una variable. 
    
En R: 
STEP(model de partida,scope=list(upper=model màxim), directon= FOREARD/BACKWARD/BOTH)    * BOTH=STEPWISE

```{r}
data1=data[,c(13,14,3,5:10,11,12)]
summary(data1)
pairs(data1)
```

Ens es útil per explorar quines var ens son útils per explicar la var resposta.


**SELECCIÓ DE VARIABLES:**

1. Mecanismes:
    FORWARD: Y ~ 1 -> afegim (una variable i anem afegin allo q es significatiu).
    BAKWARD: Y ~ . -> treiem (ajustem el model complet (totes les vars) i anem traient tot allò no significatiu.)ç
    * Es preferible el Forward si el nom de variables és gran. Els dos ens poden donar models vàlids però diferents.
    STEPWISE:  Y ~ . & Y ~ 1 -> treiem o afegim. És el mecanisme més preferible dels tres. En cada pas podem triar afegir o treure una variable. 
    
En R: 
STEP(model de partida,scope=list(upper=model màxim), directon= FOREARD/BACKWARD/BOTH)    * BOTH=STEPWISE


FORWARD: 

Ajustem primer el model null (nomes amb l'intercept) i l'indeiquem que l'abast (el upper) és el model complet.

```{r}
summary(m0<-lm(lngross~1,data1))
summary(m1a<-step(m0,scope=list(upper=lm(lngross~.,data1)),direction="forward"))
```

Resultats:

Quan te el mes (+), significa sobre el model 1, s'afegeix la variable. El que oposa none es el model que tenim ara. El AIC més petit es el millor model, ajusta millor les dades (el model d'adalt de tot). La AIC ens permet comparar dos models que tenen la mateixa Y. 

En el segon pas, tenim com a model null el del AIC -206. y va afegint variables. Però com estem en el forward, no considera la opcio de treure ninguna variable.

Així successivament.

El darrer step serà el que tendrà el none adalt de tot, i ens quedarem amb el model anterior, es a dir, sense afegir ninguna variable mes, perqùe es el que ens aporta un AIC més baix.

Despres, obtenim el summary del model triat com a millor

BACKWARD:

Partim del model complet y apartir d'aquí, li anem traeient variables. Ja no surten (+), cada variable que ens surt significa, que passa si taiem aquesta variable?

```{r}
summary(m0<-lm(lngross~.,data1))
summary(m1b<-step(m0,direction="backward"))
```

Resultats:

Oposat a lo anterior: anem traien la variable que esta més adalt (perquè es la que ens dona un AIC més baix si la traiem del model) fins que adalt de tot tenim la opció none. 


STEPWISE:

Considera treure i reitroduir variables que ja estan fora. 

```{r}
summary(m1c<-step(m0,direction="both"))
```

Resultats:

Partim del model complet, tot son menys perq considera treurer-les, i a partir del segon pas també considera introduir les que s'han tret en passes anteriors. 

El millor model obtingut és: lngross ~ lnbudget + duration + actor1_fl + cast_fl + faces_poster + GenreComedy + GenreDrama + GenreHorror.

La primera categoria de gènere (action) és la categoria base (és l'intercept).

Ara cal validar-lo.

És possible que hi hagi multicolinealitat, ho hem de estudiar intentant interpretar els coeficients. 

A més, veiem que ens surt que si el actor 1 es molt oppular, es recaptaràn menys diners (perque la beta associada al actor es -2.25), això no ens te sentit. Deu ser perquè hi ha correlacio entre actor1 y cast1 y al no poder interptretarho consierant que la resta son 0, els coeficients no estan ben estimats. Al haver multicoliniealitat (els predictors estan relacionats) no hi ha una interpretació neta (ceberis parius).

Per a que la interpretacio no es compliqui, cal que les variables explicatives siguin independents, de manera que si afegim una var nova no afecti als valors de les demes i no ens afecti a la intepretació. 

La multicolinealitat no es dolenta per a la predicciño (els valors finals de la y seran bons) però son dolents per a la inferència i la interpretació de l'efecte de les betes en la y. 
Així estudiem la correlació de les vars numèriques: 

```{r}
cor(data1[,c(1,2,3,5,8,9)]) # només vars del model final
mod=m1c
vif(mod)
```

S'observa correlació molt alta entre actor1 y cast (0.8876391)

VIF= varience inflact factor. Per detectar si hi ha multicolinealitat. Lo idel es que VIF=1 o proper a 1, perquè indica que la covariable és independent a la resta i la puc interpretar independentment de les altres. 

Però a partir de 4-5, ens preocupem per la multicolinealitat (multicolinealitat lleu) si esta al voltant de 8 és greu. 

Veient que GVIF de actor1 y cast son 4.9 y 5.1, confirmem que hi ha una multicolinealitat que s'ha d'explorar. 


A més, miram si hi ha alguna variable que no sigui significativa amb la taula de l'ANOVA:

```{r}
anova(mod)
Anova(mod,type=3)
```

Observem que el pvalor de l'actor1 entre les dues taules varia molt. La primera ens diu que no es significativa i la segona ens diu que si. 

És important que sapiguem perquè!! Què hi a al darrera??

El 0.91 compara lo que hi ha abans amb lo que s'afegeix (anova sequencial). Compara el model amb les variables lnbudget + duration y lnbudget+duration+actor1, y ens indica que es millor el modle

En la segona anova (anova marginal), que conincideix amb el summary dle model, ens mira els efectes nets de cada predictor. El model sense cada una de les variables enfront el model amb totes les variable,s Ens diu si la variable afageix o no informació a la variable repsota.

Ignorem la primera, sempre mirem la segona!!!! I veiem que totes les variables son rellevants.


VALIDACIÓ:

```{r}
par(mfrow=c(2,2))
plot(mod) #. Plot de validació.
par(mfrow=c(1,1))
```

Ens aniria bé tenir les bandes limits als plots, per tant  fem el següents gràfics:


```{r}
residualPlots(mod)
```

Normalment només mirem el general (fitted values), pero per validar el model es important tambe enfontar els residus entont cada una de les variables que tenim. I enlloc dun scatterplot, per a les categòriques tenim boxpllots.

són les distribucons dels residus entre les variables que hi ha dins del model.També es aconsellable fer-ho amb les variables que hem descartat per si es poden tornar a ficar. 

Què es el que hem d'esperar dels residus? Que la linia blava sigui horitzontal, indicant que els residus no tenen tendència, o la mediana (al boxplot) horitzontal al voltant del 0 (distribució simèrica). El fet que totes les caixes siguin simètriques ens garanteix que la var gènere ja ens explica tot el possible. 

Els dos primers plots: semplba que no és linial la liniea blava, sinó curva. Pot ser es pot justificar dient que hi ha menys punts a les parts amb menys punt i pertant s'ha d'ignorar o també que la variable té sentit que els residus siguin quadratics, etc.. 

Lo important es veure l'aleatoritat es fa respecte l'eix vertical (amunt i avall) i no el horitzontal (dreta i esquerra), ja que al ser un estudi observacional, pot ser no s'ha aleatoritzat el faces_poster i per tant pot haver valors atipics, lo important es que les variancies siguin iguals, que amumnt i avall la distribucio sigui totalment aleatoria. És això el que enspermet validar el model.

Igualment, el residualPlot ens torna una taula al final amb pvalors que el que fan es considerar introduir un terme quadratic en el model, o sigui considera que la relació no és lineal- si el pvalor es significatiu, per exemple per al p valor, (Ho: deixa el model lineal, H1: afageix un terme quadràtic) com és significatiu, ens està diguent que millor que afagim un terme quadràtic.

El tukey test el fa per tot. A la vista d'aquests pvalors, el que ens esta indicant es que si introduim el lnbudget al quadrat, la relació de la recaptacio y el logaritme del presupost millorará.

Normalitat:
```{r}
shapiro.test(resid(mod))
shapiro.test(rstudent(mod))
par(mfrow=c(1,2))
qqPlot(resid(mod))
qqPlot(rstudent(mod))
par(mfrow=c(1,1))
```

Amb els polots podem concloure que mes o menys es segueixla linia desitjada i el pvalor ens confirma la normalitat del model. 

Plot de influencia (substitueix el de la corba de nivell, del leverage i la dist de cook):

```{r}
influencePlot(mod)
```

La dist de cook es el radi de les boles. Els leverages (hat values) son a l'eix x. 
Les dades mes influents son les que tenen les boles mes grans (distancia de cook = influencia real). si estan molt a la dreta es que tenen leverage gran (influencia a priori, allunyades de la recta)

Bonferroni:
```{r}
outlierTest(mod)
```

Si el pvalor es major a 0.05, tot i que el pvalor sense ajust d'aques valor indiqui que es una obs extrema, significa que es un valor aleatoriament extrem i que per tant no el considerarem atipic

Bonferroni mira el pvalor davant totes les observacions i no nomes de la observació sola. Cal fer el test per als valors aripics per confirmar que ho son o no. 


Efectes sobre la Y y cada una de la seva escala:
```{r}
plot(allEffects(mod))
```

Serveix per interpretar l'efecte, però compte que les escales poden ser diferents!

Predicció:

Pel valor esperat(confidence) i per un cas en particular(Prediction)
```{r}
pr<-predict(mod,newdata=data.frame(lnbudget=log(20),duration=90,year="2013-2016",director_fl=0,actor1_fl=0,actor2_fl=0,cast_fl=0,faces_poster=1,Genre="Horror"),interval="confidence")
exp(pr)
pr2<-predict(mod,newdata=data.frame(lnbudget=log(20),duration=90,year="2013-2016",director_fl=0,actor1_fl=0,actor2_fl=0,cast_fl=0,faces_poster=1,Genre="Horror"),interval="prediction")
exp(pr2)
```

