---
title: "Prova Parcial Novembre 2013"
author: "Laura Julià"
date: "7/11/2017"
output: html_document
---

## PROBLEMA 1
```{r}
library(MASS)
y <- c(2.1, 1.9, 2, 2.2, 1.2, 0.8, 1.1, 0.9, 5.1, 5.2, 4.9, 4.9, 7.9, 8, 8.2, 
    7.9)
x <- c(rep(c(1, 0, -1, 0), 4), rep(c(0, 1, 0, -1), 4), rep(c(1, 1, 0, 0), 4), 
    rep(c(2, 2, -1, -1), 4))
x <- matrix(x, ncol = 4, byrow = T)
betas <- ginv(t(x) %*% x) %*% t(x) %*% y
```

#### S'ha realizat un experiment amb quatre situacions experimentals diferents i quatre rèpliques per a cadascuna.

#### Les dades són:

                 α − γ ⇒ 2.1, 1.9, 2.0, 2.2 
         
                 β − δ ⇒ 1.2, 0.8, 1.1, 0.9 
         
                 α + β ⇒ 5.1, 5.2, 4.9, 4.9 2
         
        α + 2β − γ − δ ⇒ 7.9, 8.0, 8.2, 7.9

#### Contesteu les següents qüestions:

#### (a) Quina condició ha de verificar una funció paramètrica per a que sigui estimable en aquest model?
En aquest model les f.p.e són les combinacions lineals $aα+bβ+cγ+dδ$ tals que

               a−b+c−d=0



#### (b) Indiqueu si les funcions paramètriques següents són estimables i calculeu l'estimador MQ quan sigui possible:

        (i)α 
        (ii)α + β 
        (iii)α + β + γ + δ

```{r}
library(MASS)
betas <-ginv(t(x)%*%x) %*% t(x) %*% y
betas
#i)
#No es estimable

#ii)
betas[1]+betas[2]
#[1] 5.00625

#iii)
betas[1]+betas[2]+betas[3]+betas[4]
#[1] 7

# TAMBÉ:

# i)
#No es fpe.

# ii) alpha + beta
sum(betas[1:2])
## [1] 5.006

# iii) alpha + beta + gamma + delta
sum(betas)
## [1] 7
```




#### (c) Calculeu l'estimació de les variàncies dels estimadors lineals òptims de les funcions paràmetriques estimables $α+β$ i $2α+β−γ$ i la covariància entre ells.

Primer calcularem l'estimació de la variància dels errors

```{r}
residus <- y - x %*% betas
RSS <- sum(residus^2)
sigma2 <- RSS/(16 - 3)
```

La variància estimada de l'estimació de $α+β$ és

```{r}
a <- c(1, 1, 0, 0)
as.numeric(sigma2 * t(a) %*% ginv(t(x) %*% x) %*% a)
```

La variància estimada de l'estimació de $2α+β−γ$ és
```{r}
b <- c(2, 1, -1, 0)
as.numeric(sigma2 * t(b) %*% ginv(t(x) %*% x) %*% b)
```

i la covariància

```{r}
as.numeric(sigma2 * t(a) %*% ginv(t(x) %*% x) %*% b)
```




#### (d) Feu el contrast de les dues hipòtesis

        H0(1) :α+β=5i
        H0(2) :α+β=5,2α+β−γ=7.
      
Per fer el contrast de la hipòtesi $H(1)0:α+β=5$ considerem el estadístic t de Student:
```{r}
t.est <- as.numeric((sum(betas[1:2]) - 5)/sqrt(sigma2 * t(a) %*% ginv(t(x) %*% 
    x) %*% a))
# p-valor
pt(t.est, 16 - 3, lower.tail = F) * 2
```
De manera que acceptem la hipòtesi nul·la.

Per fer el contrast de la hipòtesi $H(2)0:α+β=5,2α+β−γ=7$ ho farem com un contrast de models. El model complet és l'anterior del que ja hem calculat la suma de quadrats residual. Ara hem de fer el mateix amb el model de la hipòtesi nul·la. En primer lloc observem que $α+β=5,2α+β−γ=7$ és equivalent a $β=5−α$ i $γ=α−2$, llavors tenim:

        α−γ=2
        β−δ=5−α−δ
        α+β=5
        2α+2β−γ−δ=12−α−δ
        
Si pasem les constants a la banda de les observacions tenim un nou vector d'observacions
```{r}
y0 <- y - c(rep(2, 4), rep(5, 4), rep(5, 4), rep(12, 4))
```

La nova matriu de disseny té, en principi, dos paràmetres $α$ i $δ$.
```{r}
x0 <- c(rep(c(0, 0), 4), rep(c(-1, -1), 4), rep(c(0, 0), 4), rep(c(-1, -1), 4))
matrix(x0, ncol = 2, byrow = T)
```

però és evident que el rang és 1 i en realitat els dos paràmetres són el mateix. Així doncs la matriu de disseny de la hipòtesi nul·la es pot simplificar
```{r}
x0 <- c(rep(0, 4), rep(-1, 4), rep(0, 4), rep(-1, 4))
```

Ara ja podem calcular la suma de quadrats residual de la hipòtesi nul·la i el test F
```{r}
beta0 <- solve(t(x0) %*% x0) %*% t(x0) %*% y0
residus0 <- y0 - x0 * beta0
RSS0 <- sum(residus0^2)
f.est <- ((RSS0 - RSS)/2)/(RSS/(16 - 3))
pf(f.est, 2, 16 - 3, lower.tail = F)

```

Acceptem la hipòtesi nul·la.





## PROBLEMA 2

#### Anem a treballar amb la llista d'observacions de 934 nens i nenes en 205 famílies sobre la que Galton (1886) va basar la seva taula de freqüències i els principis de la regressió. Per estudiar la influència de l'altura dels pares en la dels  fills, Galton va fer algunes discutibles simpli cacions. Per exemple, va fer servir com a variable regressora una "mitjana" de l'altura del pare i de la mare. A més, va multiplicar per 1.08 l'altura de les dones per ajustar els seus valors als dels homes. També va considerar tots els  fills i  filles de cada família.

#### En aquest problema estudiarem la relació entre l'altura dels pares (homes) i els  lls (homes) si tu ets un home i la relació entre les mares i les  lles si tu ets una dona.

#### Les següents instruccions seleccionen les dades:


            library(HistData)
            data(GaltonFamilies)
            help(GaltonFamilies)
            # escull el teu cas:
            # sexe <- "male"
            # sexe <- "female"
            GaltonFills <- GaltonFamilies[GaltonFamilies$gender==sexe, ]
            # selecció a l'atzar d'un únic fill o filla per familia
             rownames(GaltonFills) <- 1:dim(GaltonFills)[1]
              set.seed(123)
             ff <- function(x) sample(which(GaltonFills$family==x),1)
              ind <- sapply(unique(GaltonFills$family),ff)
            # data.frame per treballar
            GaltonFills1 <- GaltonFills[ind, ]
            
Seleccionem les dades:
```{r}
library(HistData)
data(GaltonFamilies)
help(GaltonFamilies)
# escull el teu cas:
# sexe <- "male"
# sexe <- "female"
GaltonFills <- GaltonFamilies[GaltonFamilies$gender=="female", ]
# selecció a l'atzar d'un ?nic fill o filla per familia
rownames(GaltonFills) <- 1:dim(GaltonFills)[1]
set.seed(123)
ff <- function(x) as.numeric(sample(as.character(which(GaltonFills$family==x)),1))
ind <- sapply(unique(GaltonFills$family),ff)
# data.frame per treballar
GaltonFills1 <- GaltonFills[ind, ]
```

####(a) Feu un gràfic de dispersió de les variables. Feu una primera regressió lineal per identi car residus molt grans. L'anàlisi dels residus us pot ajudar.

####Indiqueu dues observacions que poden ser atípiques però no les elimineu de la base de dades.

```{r}
with(GaltonFills1, plot(father, childHeight))
```

Fem també una primera regressió:

```{r}
g <- lm(childHeight ~ father, data = GaltonFills1)
with(GaltonFills1, plot(father, childHeight))
abline(g)
```

i considerem una anàlisi gràfica dels residus amb la instrucció
```{r}
plot(g)
# Dels quatre gràfics resultants observem dos residus molt grans: 245 i 216.
plot(g, which = 1)
```




####(b) Obteniu l'estimació dels paràmetres del model (β0,β1,σ2) i calculeu el coeficient de determinació. És significativa la regressió?

Aquest apartat es pot contestar amb el següent resultat:

```{r}
(ss <- summary(g))
#i de forma individual així:
coef(g)
```
La regressió és significativa ja que F = 44.3911, 1, 177 i el seu p-valor és inferior a 0.05.




#### (c) Hi ha alguna raó per dubtar de la normalitat dels residus? La normalitat garanteix la mínima variància dels estimadors lineals en un model lineal com aquest? Explica breument com s'aconsegueix la mínima variància de les estimacions en els models lineals.

La normalitat dels residus es pot comprovar amb un gràtic
```{r}
plot(g, which = 2)
```

o amb un test
```{r}
shapiro.test(residuals(g))
```

Acceptem la normalitat dels residus.
La normalitat no és cap garantia de mínima variància. El teorema de Gauss-Markov diu que el métode dels mínims quadrats amb les tres hipòtesis de Gauss-Markov (no cal la normalitat) és el que garantitza la mínima variància dels estimadors dels paràmetres o f.p.e.


####(d) Doneu els intervals de con ança al 90% de β0, de β1 i de σ2.
L'interval de confiança al 90% és
```{r}
confint(g, level = 0.9)
```
Per a la variància del model cal fer-ho a ma
```{r}
ss$df[2]
RSS <- sum(ss$residuals^2)
c(RSS/qchisq(0.95, ss$df[2]), RSS/qchisq(0.05, ss$df[2]))
```





####(e) En un estudi fet a Espanya1 s'ha calculat que la relació entre l'altura d'un  ll home i la dels pares és:

          ESTATURA HIJO = 91.5796+0.495*ESTATURA PADRE 
          ESTATURA HIJO = 104.023 + 0.450 ∗ ESTATURA MADRE

####Contrasteu la hipòtesi H0 : β1 = 0.495 amb les dades pare/ ll (home) de Galton.

####Contrasteu la hipòtesi H0 : β1 = 0.450 amb les dades mare/ ll (home) de Galton.

####Contrasteu la hipòtesi H0 : β0 = 104.023, β1 = 0.450 amb les dades mare/ ll (home) de Galton.

####Atenció! Les dades en aquest estudi estan en centímetres (1 in = 2.54 cm). Quines són les unitats de β0 i de β1 en els models amb les dades de Galton? I quines són les unitats d'aquests mateixos paràmetres en els models amb dades espanyoles?

La primera hipòtesi es pot contrastar fent servir la t de Studen
```{r}
(0.446 - 0.495)/0.0669
```

o com un contrast de models

```{r}
g0 <- lm(childHeight ~ offset(I(0.495 * father)), data = GaltonFills1)
anova(g0, g)
```

Les dades de Galton no permeten rebutjar la hipòtesi.
Per a la següent hipòtesi cal que fem un nou model amb les dades de Galton:
```{r}
gm <- lm(childHeight ~ mother, data = GaltonFills1)
g0 <- lm(childHeight ~ offset(I(0.45 * mother)), data = GaltonFills1)
anova(g0, gm)
```

Ara rebutjem la hipòtesi nul·la.
La darrera hipòtesi es contrasta així:
```{r}
g0 <- lm(childHeight ~ 0 + offset(I(104.023/2.54 + 0.45 * mother)), data = GaltonFills1)
anova(g0, gm)
```
El rebuig de la hipòtesi era d'esperar, ja que hem rebutjat l'anterior.

En el cas de les dades de Galton, el pendent de la recta no té unitats ja que $in^2$/ $in^2$ simplifica. El mateix passa amb el pendent amb les dades espanyoles $cm^2$/ $cm^2$. El coeficient d'intercepció amb les dades de Galton està en polzades (in). En l'altre cas, les unitats són centímetres.


####(f) Feu una predicció amb IC al 99% de l'altura d'un  ll o  lla (segons el cas) amb uns pares d'altura 70 in el pare i 63 in la mare.

La predicció per a la resposta mitjana és
```{r}
predict(g, newdata = data.frame(father = 70), interval = "confidence", level = 0.99)
```
En el model que tenim no podem fer servir l'altura de la mare.



####(g) Potser seria millor tenir en compte l'altura del pare i de la mare alhora en el model. Què penses de la proposta d'en Galton de fer servir una mitjana ponderada midparentHeight de l'altura del pare i la mare? Quina proposta fas tu?

És evident que seria millor fer servir les altures de pare i mare en el model. Si tenim en compte que Galton va ser el pioner en el tema de la regressió, la idea de combinar les dues altures en una única variable regressora va ser bona. Ara podem considerar millor un model de regressió múltiple amb les dues variables com regressores o explicatives.



#### (h) Hem optat per selecionar un únic  ll o  lla (segons el cas) per familia. Quin problema pot tenir considerar tots els  lls homes o totes les  lles dones (segons el cas) de la mateixa família? Indica la hipòtesis de Gauss-Markov que pot fallar.

Si considerem tots els fills homes d'una mateixa familia podem tenir problemes de correlació (o dependència) entre les dades o els errors, això aniria en contra de la tercera condició de Gauss-Markov i el mètode dels mínims quadrats no tindria garantides les seves bones propietats.


