\SweaveOpts{prefix.string=images/grafic}


\documentclass{article}

\usepackage{hyperref}
\usepackage[english,catalan]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{Sweave}


\newcommand{\Rfunc}[1]{{\texttt{#1}}}
\newcommand{\Robj}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textit{#1}}}


\begin{document}
\SweaveOpts{concordance=TRUE}
\title{Bootstrap confidence intervals for Pearson correlation coeficient. Calculation on 'Law School' data}
\author{Oca\~na Rebull, Jordi}
\maketitle{}

We will use a sample of 82 law schools. Each faculty has the LSAT and GPA average rating of candidates for admission.
LSAT (Law School Admission Test) is the score of tests made by accredited evaluation centers, independent of the university system. 
GPA (Grade Point Average) is a score that assesses the record of each student in their pre-university studies. 
The data will be organized into a data.frame of 82 rows for law schools and 2 columns for variables LSAT and GPA

<<>>=
lawSchool <- read.table(file="Law_School.txt", header = TRUE)

n <- nrow(lawSchool)
n
@
Pearson correlation coefficient on the original sample:
<<>>=
r <- cor(lawSchool)[2,1]
r
@
Stantdard error of Pearson correlation coefficient sampling estimation. It is based on a normal parametric approximation:
<<>>=
se.r <- (1 - r*r) / sqrt(n - 3)
se.r
@

These are bivariate data. Each faculty has a pair of values (LSAT, GPA). The empirical distribution would have a bibariate density function that  gives a probability of 1/n to each observed pair. The bootstrap resampling associated with this distribution consists in choosing whole rows (schools) randomly and with replacement.\\
\\
ROW INDEXES generation randomly and with replacement (i.e, of the schools) that belong to each non-parametric boostrap resample:
<<>>=
set.seed(123)
indexs = sample(1:n,replace=TRUE)
indexs
@
The bootstrap resample will be a new data.frame formed by choosing rows 24, 65, 34, 73, ..., 10, 20, 55 of the original sample:
<<>>=
lawSchool[indexs, ]
@
Pay attention at row names, they correspond to the row in the original sample, with repetitions indicated by a notation with two points: first repetition of row 38: 38.1, etc.

Correlation coefficient calculation for the previous sample:

<<>>=
r.boot <- cor(lawSchool[indexs,])[2,1]
r.boot
@
Studentized correlation coefficient calculation for the previous sample:
<<>>=
t.r.boot <- (r.boot - r) / ((1 - r.boot*r.boot) / sqrt(n - 3))
t.r.boot
@

Or, preferably:

<<>>=
se.fact <- sqrt(n - 3)
t.r.boot <- se.fact * (r.boot - r) / (1 - r.boot*r.boot)
t.r.boot
@
Bootstap simulation:
<<>>=
B <- 10000
se.fact <- sqrt(n - 3)  # calculado al principio, una sola vez
set.seed(123)
t.r.boots <- replicate(B,
{
  r.boot <- cor(lawSchool[sample(1:n, replace = TRUE),])[2,1]
  se.fact * (r.boot - r) / (1 - r.boot*r.boot)
}
)
@

The 20 first values of the Studentized correlation coefficient:

<<>>=
t.r.boots[1:20]
@
Bootstrap-t confidence interval for the correlation coefficient:
<<>>=
alpha <- 0.05
confLevel <- 1 - alpha
@
Critical values that leave alpha/2 probability on the left tail and alpha/2 on the right tail of the bootstrap distribution:
<<>>=
quantile(t.r.boots, probs = c(alpha/2, 1 - alpha/2))
@
Bootstrap-t confidence interval:
<<>>=
icBoot.t <- r - quantile(t.r.boots, probs = c(1 - alpha/2, alpha/2)) * se.r
names(icBoot.t) <- NULL
attr(icBoot.t, "conf.level") = confLevel
icBoot.t
@
Symmetrized Bootstrap-t confidence interval:
<<>>=
t_alpha <- quantile(abs(t.r.boots), probs = 1 - alpha)
icBoot.t.sym <- r + c(-t_alpha, t_alpha) * se.r
names(icBoot.t.sym) <- NULL
attr(icBoot.t.sym, "conf.level") = confLevel
icBoot.t.sym
@

{\bf "Parametric bootstrap" version of these CI}\\
\\
We use the library 'mvtnorm' that provides the function 'rmvnorm' to generate the multivariate normal distribution.\\
Function in the library 'mvtnorm' that generates vectors according to a normal disribution with means vector 'mean' anc covariance matrix 'sigma'. For example:
<<>>=
require(mvtnorm)
rmvnorm(n = 5, mean = c(1,2), sigma = matrix(c(10,3,3,2), ncol = 2))
@
Normal resample from means and variances-covariances estimated on the original sample:
<<>>=
medias = colMeans(lawSchool)
medias
var.covs = cov(lawSchool)
var.covs

rmvnorm(n = n, mean = medias, sigma = var.covs)
@
Normal parametric bootstrap simulation:
<<>>=
B <- 10000
se.fact <- sqrt(n - 3)  # computed at first, only once
set.seed(123)
t.r.boots <- replicate(B,
{
  r.boot <- cor(rmvnorm(n = n, mean = medias, sigma = var.covs))[2,1]
  se.fact * (r.boot - r) / (1 - r.boot*r.boot)
}
)
@
# The 20 first values of studentized correlation coefficient:
<<>>=
t.r.boots[1:20]
@
The final calculation of confidence intervals would be identical to above, the only difference is the procedure to generate resamples.\\
Bootstrap-t Confidence Interval:
<<>>=
icBoot.t <- r - quantile(t.r.boots, probs = c(1 - alpha/2, alpha/2)) * se.r
names(icBoot.t) <- NULL
icBoot.t
@
Symetrized Bootstrap-t Confidence Interval:
<<>>=
t_alpha <- quantile(abs(t.r.boots), probs = 1 - alpha)
icBoot.t.sym <- r + c(-t_alpha, t_alpha) * se.r
names(icBoot.t.sym) <- NULL
attr(icBoot.t.sym, "conf.level") = confLevel
icBoot.t.sym
@
Since this is the mean score of all candidate students in each faculty, the assumption of normality is reasonable. It's interesting to compare bootstrap intervals above with the usual normal parametric confidence interval: 
<<>>=
cor.test(lawSchool[,"LSAT"], lawSchool[,"GPA"])$conf.int
@

{\bf Bootstrap-t. Standard error estimation by jackknife}\\
\\
An alternative possibility to estimate se(r): the jackknife
<<>>=
seJack.r <- function(xy) {
  n <- nrow(xy)
  r_i <- numeric(n)
  x <- xy[,1]
  y <- xy[,2]
  for (i in 1:n) {
    r_i[i] <- cor(x[-i], y[-i])
  }
  return(sqrt(((n - 1) / n) * sum((r_i - mean(r_i))^2)))
}

# Slightly fastest version:
seJ.r <- function(xy) {
  n <- nrow(xy)
  x <- xy[,1]
  y <- xy[,2]
  r_i <- vapply(1:n, function(i) cor(x[-i], y[-i]), FUN.VALUE = 0.0)
  return(sqrt(((n - 1) / n) * sum((r_i - mean(r_i))^2)))
}

require(microbenchmark)

microbenchmark(
  se.r <- seJack.r(lawSchool),
  se.r <- seJ.r(lawSchool)
)
# Nearly no difference...

se.r <- seJ.r(lawSchool)
se.r
@
Bootstrap resampling process (patience...)
<<>>=
t.r.boots <- replicate(B,
{
  lawSchool.boot <- lawSchool[sample(1:n, replace = TRUE),] 
  (cor(lawSchool.boot)[2,1] - r) / seJ.r(lawSchool.boot)
}
)
@
Bootstrap-t confidence interval:
<<>>=
icBoot.t <- r - quantile(t.r.boots, probs = c(1 - alpha/2, alpha/2)) * se.r
names(icBoot.t) <- NULL
attr(icBoot.t, "conf.level") = confLevel
icBoot.t
@
Symetrized Bootstrap-t confidence interval:
<<>>=
t_alpha <- quantile(abs(t.r.boots), probs = 1 - alpha)
icBoot.t.sym <- r + c(-t_alpha, t_alpha) * se.r
names(icBoot.t.sym) <- NULL
attr(icBoot.t.sym, "conf.level") = confLevel
icBoot.t.sym

@
{\bf Bootstrap percentile interval}\\
\\

<<>>=
B <- 10000
alpha <- 0.05
confLevel = 1 - alpha
@
B values of r*
<<>>=
r.boot <- replicate(B, cor(lawSchool[sample(1:n, replace=TRUE),])[2,1])
@
The 10 first r*:
<<>>=
r.boot[1:10]
@
Bootstrap percentile confidence interval at 95%:
<<>>=
icBoot.perc = quantile(r.boot, probs = c(alpha/2, 1 - alpha/2))
names(icBoot.perc) = NULL
attr(icBoot.perc, "conf.level") = confLevel
icBoot.perc
@
{\bf Bootstrap BCa percentile interval}\\
\\
Data matrix without row 4:
<<>>=
lawSchool[-4,]
@
Obtaining n jackknife replicas of correlation coefficient
<<>>=
r_i <- numeric(n)
for (i in 1:n) r_i[i] <- cor(lawSchool[-i,])[2,1] 

r_i <- mean(r_i) - r_i

a <- sum(r_i^3) / (6 * sum(r_i^2)^1.5)
a

z0 <- qnorm(sum(r.boot <= r) / B)
z0

zalpha <- - qnorm(alpha/2)
zalpha

icBoot.BCa = quantile(r.boot, 
  probs = c(
    pnorm(z0 + (z0 - zalpha) / (1 - a * (z0 - zalpha))), 
    pnorm(z0 + (z0 + zalpha) / (1 - a * (z0 + zalpha)))
  )
)

names(icBoot.BCa) = NULL
attr(icBoot.BCa, "conf.level") = confLevel
icBoot.BCa
@

In this example, all intervals (Bootstrap-t, percentil, BCa and normal parametric) are very similar, possibly due to the large sample size (82) and the validity of the assuption of existence of a normalizing transformation (for percentile and BCa)





\end{document}